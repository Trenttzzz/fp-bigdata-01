FROM python:3.9-slim

WORKDIR /app

# Install Python dependencies
RUN pip install --no-cache-dir \
    pyspark==3.5.0 \
    delta-spark==3.2.0 \
    mlflow==2.10.2 \
    boto3==1.34.34 \
    pandas==2.1.4 \
    scikit-learn==1.4.2 \
    kafka-python==2.0.2 \
    psycopg2-binary==2.9.9 \
    schedule==1.2.0

# Copy Spark configuration
COPY ./config/spark-defaults.conf /usr/local/lib/python3.9/site-packages/pyspark/conf/

# Copy batch trainer script
COPY ./batch-trainer/batch_training_engine.py /app/

# Create the main script to run the scheduler
# CORRECTED: Escaped the backslashes inside the format string
RUN echo '#!/usr/bin/env python3\n\
import time\n\
import schedule\n\
import logging\n\
from batch_training_engine import BatchTrainingEngine\n\
\n\
logging.basicConfig(level=logging.INFO, format=\\"%(asctime)s - %(levelname)s - %(message)s\\")\n\
logger = logging.getLogger(__name__)\n\
\n\
def main():\n\
    logger.info(\"Starting Batch Training Service...\")\n\
    trainer = BatchTrainingEngine()\n\
    \n\
    # Schedule jobs\n\
    schedule.every(30).minutes.do(trainer.check_and_train)\n\
    schedule.every().day.at(\"02:00\").do(trainer.full_retrain)\n\
    \n\
    logger.info(\"Running initial training on startup...\")\n\
    trainer.initial_training()\n\
    \n\
    logger.info(\"Batch training scheduler started.\")\n\
    while True:\n\
        schedule.run_pending()\n\
        time.sleep(60)\n\
\n\
if __name__ == \"__main__\":\n\
    main()' > /app/run_trainer.py

# Make the script executable
RUN chmod +x /app/run_trainer.py

# Run the scheduler
CMD ["python", "/app/run_trainer.py"]