{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6bd7758-0062-4e58-aa42-6a7c0e74ba16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Spark Session and MLflow configured for model training.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, length\n",
    "\n",
    "# --- START: CRITICAL FIX FOR S3/MINIO CONNECTION ---\n",
    "# Manually set environment variables for Boto3 (used by MLflow) to find MinIO.\n",
    "# This ensures that MLflow can write model artifacts to the S3 bucket.\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = f\"http://minio:9000\"\n",
    "# --- END: CRITICAL FIX ---\n",
    "\n",
    "\n",
    "# Define ALL required packages: Kafka, Delta Lake, and S3/Hadoop\n",
    "required_packages = [\n",
    "    \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0\",\n",
    "    \"io.delta:delta-spark_2.12:3.2.0\",\n",
    "    \"org.apache.hadoop:hadoop-aws:3.3.4\",\n",
    "    \"com.amazonaws:aws-java-sdk-bundle:1.12.262\"\n",
    "]\n",
    "spark_packages = \",\".join(required_packages)\n",
    "\n",
    "# Initialize Spark Session with all required packages\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"HelpfulnessModelTraining\") \\\n",
    "    .config(\"spark.jars.packages\", spark_packages) \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configure MLflow to connect to our running MLflow server\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "\n",
    "# Set a less verbose log level for cleaner output\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(\"‚úÖ Spark Session and MLflow configured for model training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc7afa74-1e3c-42e7-8d9e-312c4fac1bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading data from Silver Delta table: s3a://silver/amazon_reviews\n",
      "üìä Found 21178 reviews with 5 or more votes available for training.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "silver_path = \"s3a://silver/amazon_reviews\"\n",
    "df_model_data = None\n",
    "record_count = 0\n",
    "\n",
    "try:\n",
    "    print(f\"üì• Loading data from Silver Delta table: {silver_path}\")\n",
    "    df_silver = spark.read.format(\"delta\").load(silver_path)\n",
    "\n",
    "    # --- Feature and Target Engineering using Spark ---\n",
    "\n",
    "    # 1. Create the target variable 'is_helpful'\n",
    "    # A review is \"helpful\" if its helpfulness ratio is > 0.75 from at least 5 votes.\n",
    "    df_with_target = df_silver.withColumn(\"is_helpful\",\n",
    "        when((col(\"helpfulness_ratio\") > 0.75) & (col(\"HelpfulnessDenominator\") >= 5), 1)\n",
    "        .otherwise(0)\n",
    "    )\n",
    "\n",
    "    # 2. Create a simple feature: the length of the review text\n",
    "    df_with_features = df_with_target.withColumn(\"review_length\", length(col(\"Text\")))\n",
    "\n",
    "    # 3. Filter for a reliable training set.\n",
    "    # We only want to train on reviews that have received enough votes to be judged.\n",
    "    df_filtered = df_with_features.filter(col(\"HelpfulnessDenominator\") >= 5)\n",
    "\n",
    "    # 4. Select only the columns we need for the model\n",
    "    df_model_data = df_filtered.select(\"Text\", \"review_length\", \"Score\", \"is_helpful\")\n",
    "\n",
    "    # Force an action to see the count and cache the result for faster access later\n",
    "    record_count = df_model_data.count()\n",
    "    print(f\"üìä Found {record_count} reviews with 5 or more votes available for training.\")\n",
    "    df_model_data.cache()\n",
    "\n",
    "except AnalysisException as e:\n",
    "    print(f\"‚ùå ERROR: Could not read from Delta table. {e}\")\n",
    "    print(\"‚û°Ô∏è Please ensure the streaming ETL notebook has been running for at least 10-15 minutes.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7265b9b-b64e-47bf-8f11-8a6784ec03d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling data for training to ensure efficiency...\n",
      "Pandas DataFrame created with 20034 samples.\n",
      "üöÄ Training model pipeline...\n",
      "üìà Evaluating model...\n",
      "  Accuracy:  0.7944\n",
      "  Precision: 0.8613\n",
      "  Recall:    0.8153\n",
      "  F1-Score:  0.8377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'review-helpfulness-classifier'.\n",
      "2025/06/19 16:52:43 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: review-helpfulness-classifier, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model training complete and logged to MLflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'review-helpfulness-classifier'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "if df_model_data and record_count > 50:\n",
    "    print(\"Sampling data for training to ensure efficiency...\")\n",
    "    sample_fraction = min(1.0, 20000 / record_count)\n",
    "    pandas_df = df_model_data.sample(fraction=sample_fraction, seed=42).toPandas()\n",
    "    print(f\"Pandas DataFrame created with {len(pandas_df)} samples.\")\n",
    "\n",
    "    # --- Start ML Workflow ---\n",
    "    mlflow.set_experiment(\"Helpfulness_Prediction\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"LogisticRegression_TFIDF\"):\n",
    "        \n",
    "        # 1. Define Features (X) and Target (y)\n",
    "        X = pandas_df[['Text', 'review_length', 'Score']]\n",
    "        y = pandas_df['is_helpful']\n",
    "        \n",
    "        # 2. Split Data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "        \n",
    "        # 3. Create a Preprocessing Pipeline\n",
    "        # This handles text vectorization and scaling of numerical features separately.\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('tfidf', TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1,2)), 'Text'),\n",
    "                # CORRECTED: Added the list of columns for the scaler to act upon\n",
    "                ('scaler', StandardScaler(), ['review_length', 'Score'])\n",
    "            ])\n",
    "\n",
    "        # 4. Create the Full Model Pipeline\n",
    "        model_pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', LogisticRegression(random_state=42, class_weight='balanced', C=0.5))\n",
    "        ])\n",
    "        \n",
    "        # 5. Train the Model\n",
    "        print(\"üöÄ Training model pipeline...\")\n",
    "        model_pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # 6. Evaluate\n",
    "        print(\"üìà Evaluating model...\")\n",
    "        y_pred = model_pipeline.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"  Precision: {precision:.4f}\")\n",
    "        print(f\"  Recall:    {recall:.4f}\")\n",
    "        print(f\"  F1-Score:  {f1:.4f}\")\n",
    "        \n",
    "        # 7. Log to MLflow\n",
    "        mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
    "        mlflow.log_param(\"feature_preprocessor\", \"TFIDF_and_Scaler\")\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        \n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model_pipeline,\n",
    "            artifact_path=\"helpfulness_model\",\n",
    "            registered_model_name=\"review-helpfulness-classifier\"\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Model training complete and logged to MLflow.\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Not enough data to proceed with model training.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
